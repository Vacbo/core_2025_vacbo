## 2. Metodologia

Para a estruturação do processador, optou-se por uma metodologia de
desenvolvimento hierárquico modularizado. A hierarquia do desenvolvimento se 
refere à separação do processador em diferentes níveis de integração, e 
a modularização à divisão dos elementos que compõem o processador em arquivos separados, 
ambos métodos que foram usados em conjunto para deixar o projeto mais organizado e 
facilitar futuras iterações do projeto, como implementação de tolerância a falhas 
por meio de tripla votação por exemplo, que é a redundância de componentes para o caso de um falhar, onde 
os outros são usados para definir o valor correto a ser considerado.

Os níveis de integração do projeto foram:

- O nível mais baixo corresponde ao nível dos componentes genéricos, como está ilustrado na Figura 2;

- Acima dos genéricos, há o nível dos componentes específicos da arquitetura RV32I, ilustrados na Figura 3;

- Em seguida, o nível dos módulos, ilustrado na Figura 4. Vale mencionar que o Módulo Unidade de Controle é o único que 
implementa a lógica diretamente, sem fazer uso de componentes, já que esse módulo atua como ponte entre duas etapas do _pipeline_, mas ainda faz parte de uma etapa; 

- Há, então, o nível da CPU, onde estão os elementos que, integrados, compõem o processador, sendo esses 
as etapas do _pipeline_ e os elementos responsáveis por resolver os hazards, como 
se vê na Figura 5. Vale notar que os registradores das etapas são simbólicos, pois não existe um componente registrador específico para uso no _pipeline_. Ao invés disso, as próprias etapas do mesmo tem função de registrador.

- Também faz parte do nível da CPU a implementação dos componentes que resolvem os _hazards_ do processador, 
como está ilustrado na Figura 6. 
Se faz necessário mencionar, que devido ao fato de 
o cliente querer usar memórias externas ao processador, o projeto foi realizado de forma que as memórias desenvolvidas pelo 
grupo para propósito de teste estão fora da CPU, e por isso estão representadas apenas para propósito de facilitar o 
entendimento da mesma, caso a situação não fosse essa, o grupo teria implementado as memórias nas etapas ID e MEM, o que é mais fácil de visualizar na Figura 1 (ver Seção 1.1).

- Por fim, tem-se o nível de visão geral do projeto, com a implementação da CPU, cujo _top_ _level_ também faz parte do 
nível da CPU, e das memórias usadas para teste, como está ilustrado na Figura 7.

![](/images/reference/report_components/nivel_genericos.drawio.svg "Diagrama dos componentes genéricos implementados.")

![](/images/reference/report_components/nivel_rv32i.drawio.svg "Diagrama dos componentes RV32I implementados.")

![](/images/reference/report_components/nivel_módulos.drawio.svg "Diagrama dos módulos implementados.")

![](/images/reference/report_components/nivel_etapas.drawio.svg "Diagrama das etapas implementadas.")

![](/images/reference/report_components/nivel_processador.drawio.svg "Diagrama de Visão Geral da CPU.")

![](/images/reference/report_components/nivel_geral.drawio.svg "Diagrama de Visão Geral do Projeto.")

Já no que se refere à modularização, a mesma foi realizada seguindo a padronização explicitada no Apêndice A.

Para realizar a validação dos componentes foram utilizadas diferentes estratégias, utilizando as ferramentas: _Cocotb_, _Pytest_, _GHDL_, _Quartus_, _WaveDrom_, _Yosys_, _NetlistSVG_,_Docker_ e _GitHub Actions_. Os testes podem ser realizados tanto no ambiente de desenvolvimento, feito no _Docker_, quanto em um ambiente na nuvem, desenvolvido no _GitHub Actions_.

Para os testes do _Quartus_, utilizado para o desenvolvimento na FPGA, foi criado através da linha de comando do próprio as seguintes etapas de compilação: _Synthesis_, _Elaboration_, _Fitter_ e _Timing Analysis_. Essas etapas podem ser executadas tanto localmente, através de botões no _VSCode_, quanto no _GitHub Actions_, que executa automaticamente após um _push_ no repositório do projeto na pasta _/src_.

Com exceção do _Quartus_, os outros testes foram feitos utilizando a biblioteca _Pytest_, sendo separados os que são realizados utilizando o _Yosis_ e o _Cocotb_ em conjunto com o _GHDL_. O _Yosys_ é utilizado para a síntese e para a geração do RTL que em conjunto com o _NetlistSVG_ é possível visualizar o circuito gerado.

Enquanto o _GHDL_ e o _Cocotb_ são utilizados para a simulação dos componentes, realizando os testes de entrada e saída, e verificando se o comportamento do componente está correto, resultando em _PASS_ ou _FAIL_. Também foi incluído o _WaveDrom_ para visualizar o comportamento dos sinais em cada ciclo de clock.

O fluxo de como os testes são realizados pode ser visto na Figura 8, em que é possível observar em que momento cada teste é realizado e cada ferramenta é utilizada.

![](/images/tests.png "Diagrama do fluxo de testes.")

Para separar os testes executados pelo _Pytest_, foram utilizados markers(PYTEST, 2015), separando-os em testes de síntese, testes unitários e testes de stress. Os testes de síntese são realizados utilizando o _Yosys_, enquanto os testes unitários e de stress são realizados utilizando o _GHDL_ e o _Cocotb_.

Nos testes unitários, ou casos de testes, são inseridos valores definidos manualmente na entrada do componente e posteriormente verificado se a saída corresponde ao esperado. Um exemplo de teste unitário para o componente Somador é mostrado no Código SOMADOR:

```python:line-numbers
...

@GENERIC_ADDER.testcase
async def tb_GENERIC_ADDER_case_1(dut: GENERIC_ADDER, trace: utils.Trace):
    dut.source_1.value = BinaryValue("00000000000000000000000000000000")
    dut.source_2.value = BinaryValue("00000000000000000000000000000000")

    await trace.cycle()
    yield trace.check(dut.destination, "00000000000000000000000000000000")

    dut.source_1.value = BinaryValue("00000000000000000000000000000000")
    dut.source_2.value = BinaryValue("00000000000000000000000000000001")

    await trace.cycle()
    yield trace.check(dut.destination, "00000000000000000000000000000001")

...

```
**Código SOMADOR** - Caso de teste do componente Somador

Ao analisar testes unitários, é possível verificar se os componentes estão funcionando corretamente para um conjunto limitado de entradas. Entretanto, ao olhar para o espaço de testes coberto, ele é limitado. Uma ilustração pode ser vista na Figura 9, em que todo o espaço de testes é representado por um quadrado com fundo branco, os testes cobertos por um quadrado com fundo cinza 

![](/images/unit_test.svg "Espaço de testes coberto por testes unitários.")

Como foi solicitado e discutido com cliente, para aumentar a cobertura de testes, uma maneira é o uso de testes de stress, ou testes exaustivos. Eles consistem em testar o componente com todas as possibilidades, ou um número muito grande, de entradas possíveis. Como exemplificado na Figura 10, o espaço de testes coberto, representado por um quadrado com fundo cinza, é completo.


![](/images/exaustive.svg "Espaço de testes coberto por testes exaustivos.")

Caso fosse realizar testes exaustivos para encontrar todas as possíveis entradas seria algo inviável para a largura de dados do projeto, que é de 32 _bits_, pois seria necessário multiplicar todas as possíveis entradas. Por exemplo, para um _MUX 2X1_, que possui 2 entradas de 32 _bits_ e uma entrada de 1 _bit_, seriam necessários  2<sup>32</sup> * 2<sup>32</sup> * 2 = 2<sup>65</sup> casos de testes. Caso cada teste leve em torno de 1 ms, levariam cerca de 1169884 séculos, o que torna inviável. 

Para conseguir aumentar a chance de encontrar possíveis erros nos componentes, foi utilizada a estratégia Constraint Random Verification (CRV) (CHIPVERIFY, 2015). Ela consiste em criar um número grande de testes aleatorizados, com algumas restrições, para conseguir cobrir uma quantidade maior de cenários. Como os testes são aleatórios, quanto mais testes forem realizados, maior a chance de encontrar um erro. A Figura 11 ilustra o espaço de testes coberto pelo CRV, sendo representado por uma nuvem cinza, que se desloca pelo espaço de testes, encontrando possíveis erros.

![](/images/crv.svg "Espaço de testes coberto pelo CRV.")

A implementação do CRV foi feita utilizando um loop que executa uma certa quantidade de vezes, em conjunto com a biblioteca random, nativa do Python, que gera aleatoriamente os valores das entradas, em alguns casos para determinadas entradas, em outros para todas elas. Enquanto para a validação, o comportamento esperado do componente é simulado no _Python_ para verificar se a saída corresponde. Um exemplo da implementação para o componente _ADDER_ é mostrado no Código _Stress_.

```python:line-numbers
import random

...

@GENERIC_ADDER.testcase
async def tb_GENERIC_ADDER_stress(dut: "GENERIC_ADDER", trace: utils.Trace):
    for _ in range(1_000_000):
        source_1 = random.getrandbits(32)
        source_2 = random.getrandbits(32)
    
        dut.source_1.value = BinaryValue('{0:0{1}b}'.format(source_1, 32))
        dut.source_2.value = BinaryValue('{0:0{1}b}'.format(source_2, 32))
    
        await trace.cycle()

        message = f"source_1: {'{0:0{1}b}'.format(source_1, 32)}, source_2: {'{0:0{1}b}'.format(source_2, 32)}"

        yield trace.check(dut.destination, '{0:0{1}b}'.format(source_1+source_2, 32)[-32:], message)

...

```
**Código _Stress_** - Caso de teste de _stress_ do componente Somador


Outra estratégia utilizada foi para validar a lógica do componente utilizando uma largura de dados menor. Por meio dessa estratégia é possível conseguir realizar um teste exaustivo que consegue verificar todas as entradas possíveis. Novamente, utilizando o _MUX 2x1_ como exemplo, ao reduzir a largura de dados de 32 _bits_ para 5 _bits_, é possível atingir 2<sup>5</sup> * 2<sup>5</sup> * 2 = 2<sup>11</sup> = 2048 possibilidades, um número viável de testes. A implementação foi feita criando loops aninhados para cada entrada e depois comparando a saída com a simulação do modelo em Python. Um exemplo para o componente _ADDER_ é mostrado no Código _Stress_ _Bits_.

```python:line-numbers
...

@GENERIC_ADDER.testcase
async def tb_GENERIC_ADDER_stress_5_bits(dut: "GENERIC_ADDER", trace: utils.Trace):
    bits = 5
    for i in range(2**bits):
        for j in range(2**bits):
                source_1 = '{0:0{1}b}'.format(i, bits)
                source_2 = '{0:0{1}b}'.format(j, bits)

                dut.source_1.value = BinaryValue(source_1)
                dut.source_2.value = BinaryValue(source_2)

                message = f"source_1: {source_1}, source_2: {source_2}"
                
                await trace.cycle()
                yield trace.check(dut.destination, '{0:0{1}b}'.format(i+j, bits)[-bits:], message)

...

```
**Código _Stress_ _Bits_** - Caso de teste de _stress_ de 5 _bits_ do componente Somador

Assim, as duas estratégias de testes, CRV e redução da largura de dados, se complementam pois ao executar ambas é possível observar se o comportamento do componente muda conforme a largura de dados se altera.

### 2.1 Coleta de dados sobre o projeto

Os dados utilizados para realização deste projeto vieram de material, físico e digital, levantado pelos integrantes do projeto 
enquanto pesquisavam sobre o assunto, de conteúdo ensinado no curso de Engenharia de Computação, em específico na matéria de 
Design de Computadores lecionada por Paulo Carlos Ferreira dos Santos, de material que o orientador forneceu para ajudar na 
realização do projeto, de informações fornecidas pelo cliente, e de material que Rodrigo de Marca França forneceu.

No que se refere ao material levantado pelos integrantes, foi essencial o uso da documentação 
sobre a arquitetura de conjunto de instruções RISC-V (RISC-V INTERNATIONAL, 2019) fornecido pela RISC-V International, que é 
uma entidade sem fins lucrativos sediada na suíça, à qual o Brasil se juntou no final de fevereiro de 2024 (ver Seção 1.5) e 
que busca manter a neutralidade do desenvolvimento dessa arquitetura. Além disso, também foi encontrado um 
simulador _web_ (MARIOTTI; GIORGI, 2022) de um processador RISC-V com conjunto base de instruções para inteiros com extensão 
para multiplicação que funciona para uma arquitetura de 32 _bits_, que é precisamente o foco para este projeto, e auxiliou 
para que o fosse possível visualizar como que a arquitetura seria implementada, e como o processador interage com diferentes
instruções.

Já o conteúdo lecionado na matéria Design de Computadores, se refere ao desenvolvimento de um processador 
de arquitetura MIPS em VHDL usando o Quartus, que serviu como base de conhecimento para o desenvolvimento do projeto, já que 
foi experiência prática de desenvolvimento de um processador em VHDL, foco deste projeto, com uso da ferramenta Quartus, que 
foi necessária para validação deste projeto. Vale complementar que além 
do conhecimento adquirido nessa matéria, o curso de Engenharia da Computação também proporcionou conhecimento prático 
do uso de ferramentas como Docker, GitHub, GitHub Actions, Python e VSCode, o que resultou no estruturamento da metodologia 
de desenvolvimento técnico deste projeto.

Por sua vez, se tratando do material fornecido pelo orientador, o mais importante foi um repositório com componentes 
desenvolvidos em VHDL, onde os mesmos eram sintetizados usando GHDL, seus testes eram realizados usando Cocotb e Pytest, sendo 
que essas foram as ferramentas utilizadas no projeto para realizar os testes unitários e de integração de sistemas durante o 
projeto. Além disso, ele também forneceu livros que ajudaram no estudo da arquitetura e das suas instruções.

Já no que se refere às informações fornecidas pelos clientes, está a necessidade de modularização mencionada anteriormente na 
metodologia, assim como _feedback_ sobre as decisões tomadas ao longo do processo de desenvolvimento.

Por fim, o material fornecido por Rodrigo de Marca França foi o material de referência da agência espacial europeia, a ESA 
(European Space Agency).

### 2.2 Análise dos Dados Coletados

Na documentação sobre a arquitetura fornecida pelos materiais utilizados estão detalhadas as instruções que compõem o 
conjunto base de instruções para inteiros de 32 _bits_, sua estrutura e como elas funcionam, e o mesmo se aplica às 
instruções que compõem a extensão de multiplicação do processador (olhar Anexo A para mais informações sobre os conjuntos de 
instruções).

As instruções do conjunto base de inteiros são 40 no total, porém 3 destas instruções não foram implementadas (ECALL, 
EBREAK e FENCE) por elas serem de uso de processadores superescalares, que não faz parte do escopo. O conjunto de instruções 
da extensão de multiplicação serão implementadas se for factível a depender do tempo que sobrar após o término do 
desenvolvimento do processador funcional com as instruções do conjunto base implementadas, como acordado com o cliente.

Baseado nos conhecimentos adquiridos no curso de Engenharia de Computação, decidiu-se usar o GitHub Actions para automatizar o processo de testes CI/CD solicitados pelo cliente, e o Docker para padronizar o sistema operacional de desenvolvimento. Com 
o feedback positivo do cliente, essa metodologia de desenvolvimento se tornou parte essencial da entrega do projeto.
